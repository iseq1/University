6. Классификатор Deсision Tree (Дерево решений).

Реализовать и обучить классификатор Deсision Tree.
Обучение и тестирование произвести на датасете digits из библиотеки sklearn.
Классификатор представить в виде бинарного дерева. В качестве критерия качества разделения использовать
Information Gain (прирост информации), вычисленный на основе энтропии.
В качестве разделяющих функций использовать разделение гиперплоскостями, параллельными осям координат.
Обучение дерева произвести с помощью полного перебора.
Терминальный узел дерева создавать при выполнении хотя бы одного из трех условий:
- энтропия в узле меньше определенного порога
- глубина дерева в текущем узле дистигла максимального значения
- количество элементов обучающей выборки, достигших узла меньше определенного порога
Вычислить точность (Accuracy) и построить confusion matrix полученной модели на обучающей и тестовой выборках.
Построить гистограммы уверенностей правильно распознанных объектов и ошибочных.


Бонусные задания (необязательные):

1. Вместо энтропии в  критерия качества разделения использовать неопределенность Джини (Gini):
H(S_i) = 1 - SUM (N_i^K/N_i)^2

N_i - множество элементов достигших i узла
N_i^K - множество элементов достигших i узла и принадлежащих классу K

2. Вместо энтропии в  критерия качества разделения использовать ошибку классификации (misclassification error):
H(S_i) = 1 - max_K (N_i^K/N_i)

N_i - множество элементов достигших i узла
N_i^K - множество элементов достигших i узла и принадлежащих классу K

3. Произвести валидацию гиперпараметров с помощью рандомизированной процедуры:
	- максимальная глубина деревьев
	- критерий (энтропия/неопределенности Джини/ошибку классификации)
	- минимальное значение критерия
	- минимальное количество элементов в терминальных узлах

После валидации вычислить точность и confusion matrix на лучших параметрах.

4. Реализовать вычисление оптимальных параметров разделяющей функции на основе ограниченного перебора этих параметров.

5. В качестве разделяющих функций использовать разделение гиперплоскостями не параллельными осям координат.

6. В качестве разделяющих функций использовать разделение гиперповерхностями, полученными с помощью базисных функций phi (нелинейное разделение).